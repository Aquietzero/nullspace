---
layout: post
title: AI学习时间 08 - Transformer 与自注意力机制 3
date: 2025-05-13
categories:
    - AI
tags:
    - AI
    - 学习
    - Transformer
    - 自注意力机制
    - 大语言模型架构
---

<div class="theme-color-blue" markdown=1>
`#大语言模型` `#Transformer` `#自注意力机制`
</div>

# 复习

- **Transformer 架构**：对输入进行了理解（编码），再把理解转化为输出（解码）。
- **理解**：所谓的“理解”，实际上是一个高维稠密的向量空间。

# 稠密向量空间

把字符转化为向量可以说是一个很天才的设计，通过这样的方式，离散的字符转化为连续的向量。这种设计有几个重要考虑，回忆之前提到过的概念：

- 大模型的输入输出是向量（张量）
- Transformer 架构本质是一个函数，函数内部是向量与矩阵的运算
- 连续变量才能求导，进行反向传播，进行学习训练
- 连续变量可以构成一个度量空间，可以进行距离计算

大语言模型通过嵌入层将输入转化为向量，后续 Transformer 使用这些向量进行运算。

## 使用点积衡量相关性

最初等的衡量距离方式是勾股定理，对于两个向量 $\textbf{a} = [x_1, y_1]$ 与 $\textbf{b} = [x_2, y_2]$，它们之间的距离是：

$$
d = \sqrt{(x_1 - x_2)^2 + (y_1 - y_2)^2}
$$

但这种方式有个缺点，就是计算量很大，因为要开根号。而且这个开根号是一个非线性函数，是不能随便去掉的。所以对于大语言模型来说，嵌入维度一般很大，所以用这种方式的计算量也很大。

而两个向量的点积可以表示它们之间的“距离”（相关性），即：

$$
\textbf{a} \cdot \textbf{b} = x_1 x_2 + y_1 y_2 = |\textbf{a}||\textbf{b}| \cos \theta
$$

从一个极端的例子可以感受到这个相关性的概念，假设两个向量相互垂直，那么夹角余弦值就为 $\cos (\pi / 2) = 0$，整个点积为 $0$ 意味着两者毫无关联。点积的计算量很小，所以在大语言模型中，使用点积来衡量两个向量之间的**相关性**。

# 再谈自注意力

Transformer 只是一个架构，只是一个函数，而自注意力，是 Transformer 内部最重要的一个机制，也就是函数的定义。之前提到朴素的网络处理时序数据有一个问题，那就是丢失了时序信息，因为每次处理一个输入字符的时候，就会对这个字符进行运算，然后叠加到一个隐藏态上，到最后整个输入结束的时候，就只有一个隐藏态，字符的先后顺序已经淹没在隐藏态里了。

上次提到的一个及其简单的例子，假设输入为 $\textbf{X} = [x_1, x_2, \dots, x_T]$，如果在编码器部分使用求和算法，那么整个时间序列处理结束之后得到的隐藏状态就是所有输入之和。

$$
\textbf{H} = \sum_{t=1}^T x_t
$$

所有 $x_t$ 的顺序淹没在隐藏状态中。

## 黑盒抽象的魅力

前几次课均提到黑盒抽象，比如将 Transformer 看成是一个将输入转化为输出的黑盒，从而把抽象的“理解”看成是黑盒里面实现的内容。我们平时进行的函数提取，其实也是一种黑盒抽象。既然上面单纯叠加的方式丢失了很多信息，那我们假设有一个黑盒，能保留这种信息。

$$
\text{getContext}(x_t) = c_t
$$

代入到上面的公式，我们得到

$$
\textbf{H} = \sum_{t=1}^T \text{getContext}(x_t) = \sum_{t=1}^T c_t
$$

这个 $\text{getContext}$ 函数做了几件事情

- 将单纯的字符 $x_t$ 转化为了一个“带有上下文信息”的向量 $c_t$（自注意力机制）
- 保留了字符的时序信息，因为下标 $t$ 其实也可以作为一个计算上下文的参数（掩码）
- 转为上下文向量进行叠加，就是“理解的叠加”，而不是单纯“输入的叠加”了

由此可见，我们通过引入黑盒抽象，直接赋予了上面那个简单的求和公式一个新的含义，而从形式上来说，只是多套了一个函数而已。

## 上下文是什么?

既然 $\text{getContext}$ “提取了” 某个字符 $x_t$ 的上下文信息，那么上下文信息是什么呢？对于当前的某个 $x_t$ 来说，它只有上文，因为它的下文还没出现，所以对于 $x_t$ 来说，它的上下文信息就是它前面的所有字符。

而要衡量这些字符对 $x_t$ 的整体相关性，最简单的办法就是做一个加权平均。

$$
c_t = \sum_{i=1}^T w_i x_i
$$

其中 $w_i$ 是一个权重，它表示 $x_i$ 对 $x_t$ 的重要性。举个简单的例子，对于句子“今天天气很好”来说，我们可以构建像下面这样的权重矩阵。

|   | 今 ($x_0$) | 天 ($x_1$) | 天 ($x_2$) | 气 ($x_3$) | 很 ($x_4$) | 好 ($x_5$) |
|---|----|----|----|----|----|----|
| 今 ($x_0$) | 1  | 0  | 0  | 0  | 0  | 0  |
| 天 ($x_1$) | 0.5  | 0.5  | 0  | 0  | 0  | 0  |
| 天 ($x_2$) | 0.25  | 0.25  | 0.5  | 0  | 0  | 0  |
| 气 ($x_3$) | 0.1  | 0.2  | 0.3  | 0.4  | 0  | 0  |
| 很 ($x_4$) | 0.05  | 0.1  | 0.25  | 0.27  | 0.33  | 0  |
| 好 ($x_5$) | 0.05  | 0.05  | 0.1  | 0.2  | 0.3  | 0.5  |

那么对于对于第二个“天”来说，它的上下文可以通过下面的方式计算。

$$
\begin{align*}
c_2 = \  & 0.25 \cdot \text{Embedding}(x_0) \ + \\
& 0.25 \cdot \text{Embedding}(x_1) \ + \\
& 0.5 \cdot \text{Embedding}(x_2) \\
\end{align*}
$$

但从上面的例子也能感受到，这些所谓的“权重”应该如何得来呢？

## 自注意力机制

回到上面的计算公式，进一步进行黑盒抽象。

$$
c_t = \sum_{i=1}^T w_i x_i
$$

假如此时我们不关注如何具体地计算“权重”，而是单纯假设有一个函数能做到这件事情，令这个函数为 $\text{getWeight}$，同时我们也不直接使用 $x_i$ 的值，而是同样地包裹一个函数进行抽象，这个函数“单纯”用来获取 $x_i$ 的**值（value）**，将其称为 $\text{getValue}$，那么我们有

$$
c_t = \sum_{i=1}^T \text{getWeight}(x_t, x_i) \cdot \text{getValue}(x_i)
$$

注意到，这个函数必须接受两个参数的，因为这个权重是当前字符 $x_t$ 与它之前的某个字符 $x_i$ 的权重（回想上面的查权重表的过程）。但这依然非常抽象，这个 $\text{getWeight}$ 里面做了什么事情呢？考虑到之前提到的点积，我们可以用点积来表示两个向量之间的相关性。借用一下信息检索领域的词汇：“我们现在有一个向量 $x_t$，我们想查它跟向量 $x_i$ 之间的相关性”，那么我们可以通过以下步骤实现。

1. 我们在查找信息的时候，需要有一个“**查询（query）**”，继续使用黑盒抽象，假设我们有一个函数 $\text{getQuery}$，它能将 $x_t$ 转化为一个“查询”，那么我们有
    $$
    q_t = \text{getQuery}(x_t)
    $$
2. 我们需要有一个“**键（key）**”，继续使用黑盒抽象，假设我们有一个函数 $\text{getKey}$，它能将 $x_i$ 转化为一个“键”，那么我们有
    $$
    k_i = \text{getKey}(x_i)
    $$
3. 有了这两个值，我们就可以通过点击计算其相关性了，即
    $$
    \text{getWeight}(x_t, x_i) = q_t \cdot k_i = \text{getQuery}(x_t) \cdot \text{getKey}(x_i)
    $$

再把这一切抽象放回到原来的公式里，我们有

$$
c_t = \sum_{i=1}^T \text{getQuery}(x_t) \cdot \text{getKey}(x_i) \cdot \text{getValue}(x_i)
$$

结合之前提到的“函数无非是矩阵运算”，我们可以将上面的 $\text{get*}$ 函数定义为一个矩阵运算（忽略偏置），所以是实际上 $\text{get*}(\textbf{X}) = \textbf{W} \cdot \textbf{X}$，用对应的字母大写表示，就有整个上下文变量是通过如下方式得到的 **（这里忽略了一些细节，但不影响理解，忽略的部分包括矩阵形状，维度缩放，以及掩码机制）**。

$$
\textbf{C} = \textbf{Q} \cdot \textbf{K} \cdot \textbf{V} \cdot \textbf{X}
$$

真正的公式为

$$
\text{Attention}(\textbf{Q}, \textbf{K}, \textbf{V}) 
= \text{softmax}\bigg( \frac{\textbf{Q}\textbf{K}^\intercal}{\sqrt{D}}\bigg)\textbf{V}
$$

这个“上下文抽象”的机制，就成为**自注意力机制**。在此稍作提点的是，$\textbf{Q} \cdot \textbf{K}$ 是权重，权重需要归一化，也就是和必须为 $1$，所以需要使用 $\text{softmax}$ 函数。而除以维度是基于训练稳定性的考虑。